{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382f0145-114c-4bb0-968e-09701400261f",
   "metadata": {},
   "source": [
    "# Q1. Explain the difference between greedy and non-greedy syntax with visual terms in as few words as possible. What is the bare minimum effort required to transform a greedy pattern into a non-greedy one? What characters or characters can you introduce or change?\n",
    "\n",
    "A1. In regular expressions, a greedy pattern matches the longest possible substring, while a non-greedy pattern matches the shortest possible substring. Greedy patterns are denoted by the + and * quantifiers, while non-greedy patterns are denoted by +? and *?.\n",
    "\n",
    "For example, consider the string 'abbbbab' and the pattern 'ab*'. A greedy match would be 'abbbb', while a non-greedy match would be 'a'. The bare minimum effort required to transform a greedy pattern into a non-greedy one is to append a ? to the quantifier.\n",
    "\n",
    "Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d3ac23-1a04-45a8-91c0-2c0c7b7a0a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy match: abbbb\n",
      "Non-greedy match: a\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Greedy match\n",
    "string = 'abbbbab'\n",
    "pattern = 'ab*'\n",
    "match = re.search(pattern, string)\n",
    "print('Greedy match:', match.group())\n",
    "\n",
    "# Non-greedy match\n",
    "pattern = 'ab*?'\n",
    "match = re.search(pattern, string)\n",
    "print('Non-greedy match:', match.group())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044cbc0-6177-4e9c-9ab0-0f79a10a56c8",
   "metadata": {},
   "source": [
    "# Q2. When exactly does greedy versus non-greedy make a difference?  What if you're looking for a non-greedy match but the only one available is greedy?\n",
    "\n",
    "Greedy versus non-greedy syntax makes a difference when there is a possibility of multiple matches in the same string. Greedy syntax will match as much as it can while still allowing the remainder of the pattern to match, whereas non-greedy syntax will match as little as possible to allow the remainder of the pattern to match.\n",
    "\n",
    "For example, consider the string text = 'aabaaab' and the pattern pattern = 'a.*b'. The greedy match for this pattern on this string would be 'aabaaab', while the non-greedy match would be 'aab'.\n",
    "\n",
    "If you're looking for a non-greedy match but the only one available is greedy, you can transform the pattern into a non-greedy one by appending a ? to the .* quantifier. For example, changing the pattern to pattern = 'a.*?b' would give the non-greedy match of 'aab'.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c941226c-e6e9-4e9e-9549-c55125a829ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aabaaab\n",
      "aab\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Greedy match\n",
    "text = 'aabaaab'\n",
    "pattern = 'a.*b'\n",
    "greedy_match = re.search(pattern, text)\n",
    "print(greedy_match.group())  # Output: aabaaab\n",
    "\n",
    "# Non-greedy match\n",
    "text = 'aabaaab'\n",
    "pattern = 'a.*?b'\n",
    "nongreedy_match = re.search(pattern, text)\n",
    "print(nongreedy_match.group())  # Output: aab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e3828-995d-4841-b774-5fa0d65c330c",
   "metadata": {},
   "source": [
    "# Q3. In a simple match of a string, which looks only for one match and does not do any replacement, is the use of a nontagged group likely to make any practical difference?\n",
    "\n",
    "In a simple match of a string, which looks only for one match and does not do any replacement, the use of a nontagged group is not likely to make any practical difference. A nontagged group is simply a way to group parts of a regular expression together without capturing the matched substring for later use. If you're not interested in capturing the matched substring, there's no need to use a nontagged group.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d1e5ee-3593-4b9c-838b-dd767b64c69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Simple match without nontagged group\n",
    "text = 'hello world'\n",
    "pattern = 'hello'\n",
    "match = re.search(pattern, text)\n",
    "print(match.group())  # Output: hello\n",
    "\n",
    "# Simple match with nontagged group\n",
    "text = 'hello world'\n",
    "pattern = '(hello)'\n",
    "match = re.search(pattern, text)\n",
    "print(match.group(1))  # Output: hello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a3f006-4126-4aaa-84e7-dff4752904bf",
   "metadata": {},
   "source": [
    "# Q4. Describe a scenario in which using a nontagged category would have a significant impact on the program's outcomes.\n",
    "\n",
    "A scenario in which using a nontagged category would have a significant impact on the program's outcomes is when you're doing a search-and-replace operation and you want to preserve some parts of the original string while replacing others. By using nontagged categories, you can group parts of the pattern together without capturing them, and then refer to those groups in the replacement string using backreferences.\n",
    "\n",
    "For example, suppose you have a string containing a list of names in the format \"last name, first name\", and you want to convert it to the format \"first name last name\". You could use the following regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7fa2af-f604-48f3-bec4-7d039bf6f9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Smith\n",
      "Jane Doe\n",
      "Bob Johnson\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = 'Smith, John\\nDoe, Jane\\nJohnson, Bob'\n",
    "pattern = '(\\w+), (\\w+)'\n",
    "replacement = r'\\2 \\1'\n",
    "new_text = re.sub(pattern, replacement, text)\n",
    "print(new_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4d499-4867-462c-ae82-9e0bf712d87e",
   "metadata": {},
   "source": [
    "# Q5. Unlike a normal regex pattern, a look-ahead condition does not consume the characters it examines. Describe a situation in which this could make a difference in the results of your program.\n",
    "\n",
    "A look-ahead condition can be useful when you need to match a pattern that is followed by another pattern, but you don't want to include the second pattern in the match. For example, suppose you have a list of words and you want to find all the words that are followed by the word \"apple\". You can use a positive look-ahead to match the word without consuming the characters that come after it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b403cd63-ab4c-4be1-8f23-c3c43a1ae23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banana', 'cherry', 'grape']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"banana apple, cherry apple, grape apple\"\n",
    "pattern = r\"\\w+(?=\\sapple)\"  # positive look-ahead for \" apple\"\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "print(matches)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ff3251-bea4-42cb-9679-e13ded3b5c65",
   "metadata": {},
   "source": [
    "# Q6. In standard expressions, what is the difference between positive look-ahead and negative look-ahead?\n",
    "\n",
    "Positive look-ahead ((?=pattern)) matches the current position if the next characters match pattern, but it doesn't consume those characters. Negative look-ahead ((?!pattern)) matches the current position if the next characters do not match pattern, but it also doesn't consume those characters.\n",
    "\n",
    "For example, let's say you have a string of URLs, but you want to exclude any URLs that end in \".png\". You can use a negative look-ahead to exclude those URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c8f197-76ae-462b-afde-86d837043479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://example.com/test.html', 'http://example.com/image.png']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"http://example.com/test.html http://example.com/image.png\"\n",
    "pattern = r\"http:\\/\\/[\\w\\.\\/]+(?!\\.png)\"  # negative look-ahead for \".png\"\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "print(matches)  # Output: ['http://example.com/test.html']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed4c7a4-3cb2-4662-bed1-3a193b167aeb",
   "metadata": {},
   "source": [
    "# Q7. What is the benefit of referring to groups by name rather than by number in a standard expression?\n",
    "\n",
    "Referring to groups by name rather than by number makes the code more readable and less error-prone. When you use named groups, you can refer to them by their names in the rest of the regular expression, as well as in any code that uses the match object.\n",
    "\n",
    "For example, suppose you have a list of phone numbers in the format (123) 456-7890, and you want to extract the area code and the exchange number. Here's how you can use named groups to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312cf0a4-c413-428c-8aad-d04e4dab51d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area code: 123 Exchange: 456\n",
      "Area code: 456 Exchange: 789\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Phone numbers: (123) 456-7890, (456) 789-0123\"\n",
    "pattern = r\"\\((?P<area>\\d{3})\\) (?P<exchange>\\d{3})-\\d{4}\"  # named groups for area code and exchange\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "for match in matches:\n",
    "    print(\"Area code:\", match[0], \"Exchange:\", match[1])  # Access named groups using their names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a88bd-4375-431d-b66d-e72c24fe9bb3",
   "metadata": {},
   "source": [
    "# Q8. Can you identify repeated items within a target string using named groups, as in \"The cow jumped over the moon\"?\n",
    "\n",
    "Yes, you can use named groups to match repeated items in a target string. For example, suppose you have a string containing multiple occurrences of the same word, and you want to match only the words that occur more than once. Here's how you can use a named group to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88acca43-99e2-49c8-84d3-e1e4dc6dd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "pattern = r\"\\b(?P<word>\\w+)\\b.*\\b(?P=word)\\b\"  # named group for word\n",
    "\n",
    "matches = re.findall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d47fe0-dc57-457e-bcc0-b058ce94fbf9",
   "metadata": {},
   "source": [
    "# Q9. When parsing a string, what is at least one thing that the Scanner interface does for you that the re.findall feature does not?\n",
    "\n",
    "A9. The Scanner interface in Python provides more fine-grained control over string parsing than the re.findall feature. Specifically, the Scanner allows you to specify a set of patterns that match different types of tokens in the input string, and then iterate through the tokens one by one. This can be useful in cases where you need to perform different operations on different types of tokens. For example, consider the following code snippet:\n",
    "\n",
    "In this example, we define a Scanner that recognizes three types of tokens: WORDs (sequences of letters), NUMBERs (sequences of digits), and PUNCTUATION (any non-alphanumeric characters). We also specify a regular expression pattern to match whitespace, but we don't assign a function to handle it (i.e., we pass None as the second argument to re.Scanner).\n",
    "\n",
    "We then use the scanner.scan() method to extract tokens from an input string. This method returns a tuple of two elements: the first is a list of all the recognized tokens, and the second is the remainder of the input string that was not matched by any of the patterns. Finally, we iterate through the list of tokens and print each one. The output of this script is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6576aa16-83b2-483b-b48a-4a192e539998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WORD', 'The')\n",
      "('WORD', 'quick')\n",
      "('WORD', 'brown')\n",
      "('WORD', 'fox')\n",
      "('PUNCTUATION', ',')\n",
      "('WORD', 'jumped')\n",
      "('WORD', 'over')\n",
      "('WORD', 'the')\n",
      "('WORD', 'lazy')\n",
      "('WORD', 'dog')\n",
      "('PUNCTUATION', '.')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "scanner = re.Scanner([\n",
    "    (r'[a-zA-Z]+', lambda scanner, token: ('WORD', token)),\n",
    "    (r'[0-9]+', lambda scanner, token: ('NUMBER', int(token))),\n",
    "    (r'[^\\w\\s]+', lambda scanner, token: ('PUNCTUATION', token)),\n",
    "    (r'\\s+', None)\n",
    "])\n",
    "\n",
    "input_str = 'The quick brown fox, jumped over the lazy dog.'\n",
    "\n",
    "tokens, remainder = scanner.scan(input_str)\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed7488-6dd8-4bdd-8be3-e64a0a05a2fb",
   "metadata": {},
   "source": [
    "# Q10. Does a scanner object have to be named scanner?\n",
    "\n",
    "A10. No, a Scanner object can be named anything you like, as long as the name is a valid Python identifier. For example, you could write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "410aea96-2648-41b2-9d36-ca43b8abb4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WORD', 'The')\n",
      "('WORD', 'quick')\n",
      "('WORD', 'brown')\n",
      "('WORD', 'fox')\n",
      "('PUNCTUATION', ',')\n",
      "('WORD', 'jumped')\n",
      "('WORD', 'over')\n",
      "('WORD', 'the')\n",
      "('WORD', 'lazy')\n",
      "('WORD', 'dog')\n",
      "('PUNCTUATION', '.')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "my_scanner = re.Scanner([\n",
    "    (r'[a-zA-Z]+', lambda scanner, token: ('WORD', token)),\n",
    "    (r'[0-9]+', lambda scanner, token: ('NUMBER', int(token))),\n",
    "    (r'[^\\w\\s]+', lambda scanner, token: ('PUNCTUATION', token)),\n",
    "    (r'\\s+', None)\n",
    "])\n",
    "\n",
    "input_str = 'The quick brown fox, jumped over the lazy dog.'\n",
    "\n",
    "tokens, remainder = my_scanner.scan(input_str)\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5670c0-ac8b-4462-bb7c-92a321c986a8",
   "metadata": {},
   "source": [
    "This code defines a Scanner object named my_scanner instead of scanner. The name of the object is not important; what matters is that you use the same name consistently when calling its methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
